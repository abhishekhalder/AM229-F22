{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Problem 1. [100 points] Ability of Sports Teams\n\nConsider $n$ teams competing each other in a sports (e.g., soccer, football or basketball) tournament. Some teams are stronger than others due to reasons such as players' skills, coaching and staff support, amount of practice etc. We want to model each of the $n$ team's ability $a_x \\in [0,1]\\;\\forall x = 1,...,n$. \n\n**The purpose of this problem is to learn the ability vector $a\\in[0,1]^{n}$ from historical game outcome data.** Once determined, we may use $a\\in[0,1]^{n}$ to predict the outcome of a future sports game.\n\n## (a) [50 points] Maximum Likelihood Estimate\n\nWhen teams $x$ and $y$ play each other, the probability that team $x$ wins is equal to $\\mathbb{P}\\left(a_x - a_y + v > 0\\right)$ where the noise $v\\sim\\mathcal{N}\\left(0,\\sigma^{2}\\right)$, the normal distribution with mean zero and variance $\\sigma^2$. The noise random variable $v$ models things like players' injuries, weather during the game, players' mental stress etc.\n\nSuppose we are given historical game outcome data $\\left(x^{(i)},y^{(i)},z^{(i)}\\right)$ for $i=1,...,m$ games, meaning that game $i$ was played between teams $x^{(i)}$ and $y^{(i)}$, and the result was \n$$z^{(i)} = \\begin{cases}\n+1 & \\text{if team $x^{(i)}$ won},\\\\\n-1 & \\text{if team $y^{(i)}$ won}.\n\\end{cases}$$\nWe assume that there were no ties. We collect this historical data in a matrix $H\\in\\mathbb{R}^{m\\times n}$ whose each row denotes a game, and each column denotes a team, i.e.,\n$$H_{ij} = \\begin{cases}\n+z^{(i)} & \\text{if $j=x^{(i)}$},\\\\\n-z^{(i)} & \\text{if $j=y^{(i)}$},\\\\\n0 & \\text{otherwise}.\n\\end{cases}$$\nAssuming the outcomes of past games were statistically independent, formulate computing the maximum likelihood estimate of the ability vector $a^{*}_{\\text{MLE}}$ as an optimization problem where matrix $H$ appears as a known parameter. **Explain all mathematical derivation, including why the derived problem is convex**.\n\n**Hints:** You need to derive an optimization problem over the decision variable $a\\in[0,1]^{n}$. If $v\\sim\\mathcal{N}\\left(0,\\sigma^{2}\\right)$ then $\\frac{v}{\\sigma} \\sim\\mathcal{N}(0,1)$, the standard normal distribution. The cumulative distribution function for standard normal distribution is discussed in Lec. 10, p. 14.\n\n## Solution for part 1(a):\nWhen teams $x$ and $y$ play each other, the probability that team $x$ wins is equal to \n\\begin{align*}\n\\mathbb{P}\\left(a_x - a_y + v > 0\\right) &= \\mathbb{P}\\left(\\frac{v}{\\sigma} > \\frac{a_y - a_x}{\\sigma}\\right) = 1 - \\mathbb{P}\\left(\\frac{v}{\\sigma} \\leq \\frac{a_y - a_x}{\\sigma}\\right) = 1 - \\Phi\\left(\\frac{a_y - a_x}{\\sigma}\\right) = \\Phi\\left(\\frac{a_x - a_y}{\\sigma}\\right),\n\\end{align*}\nwhere $\\Phi(r) := \\frac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^{r}\\exp\\left(-\\frac{t^2}{2}\\right){\\rm{d}}t$, $r\\in\\mathbb{R}$, is the standard normal CDF discussed in Lec. 10, p. 14. The last equality follows from $1-\\Phi(r)=\\Phi(-r)$ for all $r\\in\\mathbb{R}$. To see this, simply notice that\n\\begin{align*}\n\\Phi(r) = \\frac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^{r}\\exp\\left(-\\frac{t^2}{2}\\right){\\rm{d}}t \\overset{t\\mapsto -\\tau}{=} \\frac{1}{\\sqrt{2\\pi}}\\int_{-r}^{+\\infty}\\exp\\left(-\\frac{\\tau^2}{2}\\right){\\rm{d}}\\tau, \\quad(*)\n\\end{align*}\nand that \n\\begin{align*}\n\\lim_{r\\rightarrow\\infty}\\Phi(r) = 1 = \\frac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^{+\\infty}e^{-\\tau^2/2}{\\rm{d}}\\tau = \\underbrace{\\frac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^{-r}e^{-\\tau^2/2}{\\rm{d}}\\tau}_{\\Phi(-r)} + \\frac{1}{\\sqrt{2\\pi}}\\int_{-r}^{+\\infty}e^{-\\tau^2/2}{\\rm{d}}\\tau \\quad\\Rightarrow\\quad \\underbrace{\\frac{1}{\\sqrt{2\\pi}}\\int_{-r}^{+\\infty}e^{-\\tau^2/2}{\\rm{d}}\\tau}_{\\Phi(r)\\;\\text{from}\\;(*)} = 1 - \\Phi(-r).\n\\end{align*}\nFor $i=1,...,m$, let $h_i$ denote the $i$th row of $H\\in\\mathbb{R}^{m\\times n}$. Thanks to statistical intedependece, the log-likelihood equals\n$$\\log\\prod_{i=1}^{m}\\Phi\\left(\\langle h_i/\\sigma, a\\rangle\\right) = \\sum_{i=1}^{m}\\log\\Phi\\left(\\langle h_i/\\sigma, a\\rangle\\right).$$\nHence, the maximum likelihood estimate is\n$$a^{*}_{\\text{MLE}} = \\underset{a\\in[0,1]^{n}}{\\arg\\max}\\sum_{i=1}^{m}\\log\\Phi\\left(\\langle h_i/\\sigma, a\\rangle\\right).\\quad(**)$$\nAs discussed in Lec. 10, p. 14, $\\log\\Phi\\left(\\cdot\\right)$ is a concave function, and so is its post-composition with affine map. Sum of concave being concave, the objective in $(**)$ is a concave function. The constraint set being the unit cube (i.e., a polyhedron), is a convex set. Therefore, $(**)$ is a convex optimization problem. \n\n**Side remark:** We can write $(**)$ more succinctly as $\\underset{a\\in[0,1]^{n}}{\\arg\\max}\\langle\\boldsymbol{1},\\log\\Phi\\left(Ha/\\sigma\\right)\\rangle$ where $\\Phi(\\cdot)$ and $\\log(\\cdot)$ act elementwise on vector argument. \n\n## (b) [50 points] Numerical Solution\n\nFix $\\sigma = 0.25$, and $n=10$ teams playing $m=45$ matches in a tournament where each team plays another team once. For row index $i=1,...,m$, the tuple $\\left(x^{(i)},y^{(i)},z^{(i)}\\right)$ are given by the following array of 45 rows and 3 columns:\n$$\\texttt{[1 2 1;\n1 3 1;\n1 4 1;\n1 5 1;\n1 6 1;\n1 7 1;\n1 8 1;\n1 9 1;\n1 10 1;\n2 3 -1;\n2 4 -1;\n2 5 -1;\n2 6 -1;\n2 7 -1;\n2 8 -1;\n2 9 -1;\n2 10 -1;\n3 4 1;\n3 5 -1;\n3 6 -1;\n3 7 1;\n3 8 1;\n3 9 1;\n3 10 1;\n4 5 -1;\n4 6 -1;\n4 7 1;\n4 8 1;\n4 9 -1;\n4 10 -1;\n5 6 1;\n5 7 1;\n5 8 1;\n5 9 -1;\n5 10 1;\n6 7 1;\n6 8 1;\n6 9 -1;\n6 10 -1;\n7 8 1;\n7 9 1;\n7 10 -1;\n8 9 -1;\n8 10 -1;\n9 10 1]}$$\nUse the above data to write a code to first construct the matrix $H\\in\\mathbb{R}^{m\\times n}$, and then compute $a^{*}_{\\text{MLE}}$ in the same code via cvx/cvxpy/Convex.jl. **Please submit your numerically computed $a^{*}_{\\text{MLE}}$ as well as the code.**\n\n## Solution for part 1(b):\n\nPlease see the posted MATLAB code $\\texttt{AM229HW8P1b.m}$ in CANVAS File section, folder: Homework Problems and Solutions. This code computes\n$$a^{*}_{\\text{MLE}}=\\begin{pmatrix}\n1.0000\\\\\n0.0000\\\\\n0.6829\\\\\n0.3696\\\\\n0.7946\\\\\n0.5779\\\\\n0.3795\\\\\n0.0895\\\\\n0.6736\\\\\n0.5779\n\\end{pmatrix}.$$",
      "metadata": {}
    }
  ]
}